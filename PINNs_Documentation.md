# Physics-Informed Neural Networks (PINNs) for Rainfall-Runoff Modeling

## Complete Documentation and User Guide

---

## ğŸ“‹ Table of Contents

1. [Overview](#1-overview)
2. [Physical Model](#2-physical-model)
3. [Mathematical Formulation](#3-mathematical-formulation)
4. [Implementation Details](#4-implementation-details)
5. [Usage Guide](#5-usage-guide)
6. [Parameter Tuning](#6-parameter-tuning)
7. [Troubleshooting](#7-troubleshooting)
8. [Extensions and Modifications](#8-extensions-and-modifications)
9. [References](#9-references)

---

## 1. Overview

### 1.1 Purpose

This notebook implements a **Physics-Informed Neural Network (PINN)** to simulate rainfall-runoff processes on an inclined plane. The model solves the 2D Shallow Water Equations (SWEs) using a neural network approach that enforces physical laws through the loss function.

### 1.2 Key Features

- **Physics-Informed Learning**: Neural network trained to satisfy shallow water PDEs
- **Rainfall Source Term**: Time-varying precipitation input (default: 50 mm/hr)
- **Terrain Modeling**: Simple inclined plane with customizable slope
- **Boundary Conditions**: Wall boundaries with zero normal velocity
- **Automatic Differentiation**: PyTorch autograd for computing PDE residuals
- **Visualization**: 3D surface and 2D velocity field animations

### 1.3 Simulation Scenario

```
Domain:          1m Ã— 1m Ã— 300s (spatial Ã— temporal)
Terrain:         5% slope in x-direction
Rainfall:        50 mm/hr for first 180 seconds
Initial State:   Nearly dry bed (1 Î¼m water depth)
Boundaries:      All walls (no-penetration conditions)
```

### 1.4 What You'll Learn

- How to implement PINNs for PDE-governed systems
- Incorporating source terms and boundary conditions
- Using automatic differentiation for PDE residuals
- Training strategies for physics-informed models
- Visualizing spatiotemporal simulation results

---

## 2. Physical Model

### 2.1 Phenomenon

The model simulates **overland flow** generated by rainfall on a sloping surface, which is fundamental for understanding:

- **Runoff generation mechanisms**: How rainfall converts to surface flow
- **Surface water movement patterns**: Flow directions and velocities
- **Flood dynamics on hillslopes**: Water accumulation and drainage
- **Erosion potential assessment**: High-velocity flow regions

### 2.2 Governing Equations

#### 2.2.1 Shallow Water Equations (SWEs)

The 2D shallow water equations describe conservation of mass and momentum for thin fluid layers:

**Continuity Equation** (Mass Conservation):
```
âˆ‚h/âˆ‚t + âˆ‚(hu)/âˆ‚x + âˆ‚(hv)/âˆ‚y = R(x,y,t)
```

Expanded form:
```
âˆ‚h/âˆ‚t + uÂ·âˆ‚h/âˆ‚x + hÂ·âˆ‚u/âˆ‚x + vÂ·âˆ‚h/âˆ‚y + hÂ·âˆ‚v/âˆ‚y = R
```

**X-Momentum Equation**:
```
âˆ‚u/âˆ‚t + uÂ·âˆ‚u/âˆ‚x + vÂ·âˆ‚u/âˆ‚y + gÂ·âˆ‚(h+z)/âˆ‚x + fÂ·u = 0
```

**Y-Momentum Equation**:
```
âˆ‚v/âˆ‚t + uÂ·âˆ‚v/âˆ‚x + vÂ·âˆ‚v/âˆ‚y + gÂ·âˆ‚(h+z)/âˆ‚y + fÂ·v = 0
```

#### 2.2.2 Variable Definitions

| Symbol | Description | Units | Typical Range |
|--------|-------------|-------|---------------|
| h(x,y,t) | Water depth | m | 0 - 0.1 |
| u(x,y,t) | X-velocity | m/s | -1 to 1 |
| v(x,y,t) | Y-velocity | m/s | -1 to 1 |
| z(x,y) | Terrain elevation | m | 0.05 - 0.1 |
| Î¶(x,y,t) | Water surface elevation | m | 0.05 - 0.15 |
| R(x,y,t) | Rainfall intensity | m/s | 0 - 1Ã—10â»âµ |
| g | Gravity | m/sÂ² | 9.81 |
| f | Friction coefficient | 1/s | 0.001 - 0.1 |

#### 2.2.3 Physical Assumptions

1. **Shallow water**: Vertical velocities negligible (h << L)
2. **Hydrostatic pressure**: Pressure gradient is hydrostatic
3. **Free surface**: Water-air interface is free boundary
4. **Incompressible fluid**: Water density is constant
5. **No viscous stresses**: Turbulence modeled via friction
6. **Simplified friction**: Linear friction (not full Manning)

### 2.3 Terrain Configuration

#### 2.3.1 Inclined Plane

The terrain is defined as:
```
z(x,y) = z_max - slope Ã— x = 0.1 - 0.05x
```

Properties:
- **Type**: Linear inclined plane
- **Slope**: 5% (0.05 m/m) in x-direction
- **Maximum elevation**: 0.1 m at x=0
- **Minimum elevation**: 0.05 m at x=1
- **Y-independence**: Uniform across y-direction

#### 2.3.2 Slope Derivatives

```
âˆ‚z/âˆ‚x = -0.05  (constant downhill gradient)
âˆ‚z/âˆ‚y = 0      (no cross-slope)
```

These gradients drive the flow in the momentum equations.

### 2.4 Boundary Conditions

#### 2.4.1 Wall Boundaries (All Four Sides)

- **Left wall (x=0)**: `u = 0` (no x-flow through boundary)
- **Right wall (x=1)**: `u = 0` (no x-flow through boundary)  
- **Bottom wall (y=0)**: `v = 0` (no y-flow through boundary)
- **Top wall (y=1)**: `v = 0` (no y-flow through boundary)

These are **no-penetration** conditions that prevent water from leaving the domain.

#### 2.4.2 Mathematical Implementation

The BC loss enforces:
```
L_BC = MSE(u|_{x=0}) + MSE(u|_{x=1}) + MSE(v|_{y=0}) + MSE(v|_{y=1})
```

### 2.5 Initial Conditions

At t=0:
- **Water depth**: `h(x,y,0) = 1Ã—10â»â¶ m` (nearly dry)
- **X-velocity**: `u(x,y,0) = 0` (at rest)
- **Y-velocity**: `v(x,y,0) = 0` (at rest)
- **Water surface**: `Î¶(x,y,0) = z(x,y) + 1Ã—10â»â¶`

The simulation starts with an essentially dry bed that gradually wets up due to rainfall.

### 2.6 Rainfall Source Term

#### 2.6.1 Time-Varying Rainfall

```python
R(t) = { R_const  if t_start â‰¤ t â‰¤ t_end
       { 0        otherwise
```

Default parameters:
- **Intensity**: R_const = 50 mm/hr = 1.39Ã—10â»âµ m/s
- **Duration**: t_start = 0s, t_end = 180s (3 minutes)
- **Total precipitation**: 50 mm/hr Ã— 3/60 hr = 2.5 mm

#### 2.6.2 Physical Interpretation

- **Light rain**: 1-2 mm/hr
- **Moderate rain**: 2-10 mm/hr
- **Heavy rain**: 10-50 mm/hr
- **Violent rain**: >50 mm/hr (default scenario)

---

## 3. Mathematical Formulation

### 3.1 Neural Network Architecture

#### 3.1.1 Network Structure

The PINN maps normalized spatiotemporal coordinates to flow variables:

```
NN: (xÌ‚, Å·, tÌ‚) â†’ (Î¶, u, v)
```

Where:
- **Input**: (xÌ‚, Å·, tÌ‚) âˆˆ [-1, 1]Â³ (normalized coordinates)
- **Output**: (Î¶, u, v) âˆˆ â„Â³ (physical variables)

**Layer-by-Layer Breakdown**:
```
Layer 1: Linear(3 â†’ 64)  + Tanh    [input projection]
Layer 2: Linear(64 â†’ 64) + Tanh    [hidden layer 1]
Layer 3: Linear(64 â†’ 64) + Tanh    [hidden layer 2]
Layer 4: Linear(64 â†’ 64) + Tanh    [hidden layer 3]
Layer 5: Linear(64 â†’ 3)            [output projection]
```

**Parameter Count**:
- Layer 1: 3Ã—64 + 64 = 256
- Layers 2-4: 3Ã—(64Ã—64 + 64) = 12,480
- Layer 5: 64Ã—3 + 3 = 195
- **Total**: ~17,000 parameters

#### 3.1.2 Activation Function: Tanh

Chosen for:
- **Smoothness**: Infinitely differentiable (essential for PDEs)
- **Bounded outputs**: Prevents gradient explosion
- **Non-linearity**: Captures complex flow patterns
- **Zero-centered**: Better gradient flow than sigmoid

### 3.2 Loss Function

#### 3.2.1 Total Loss

```
L_total = w_pdeÂ·L_pde + w_icÂ·L_ic + w_bcÂ·L_bc + w_physÂ·L_phys
```

Default weights:
- w_pde = 1.0 (baseline)
- w_ic = 150.0 (strong initial condition enforcement)
- w_bc = 150.0 (strong boundary enforcement)
- w_phys = 20.0 (moderate physical constraint)

#### 3.2.2 PDE Residual Loss (L_pde)

Measures how well the NN satisfies the governing equations:

```
L_pde = (1/N_coll) Î£ (râ‚Â² + râ‚‚Â² + râ‚ƒÂ²)
```

Where the residuals are:

**Continuity residual (râ‚)**:
```
râ‚ = âˆ‚h/âˆ‚t + uÂ·âˆ‚h/âˆ‚x + hÂ·âˆ‚u/âˆ‚x + vÂ·âˆ‚h/âˆ‚y + hÂ·âˆ‚v/âˆ‚y - R
```

**X-momentum residual (râ‚‚)**:
```
râ‚‚ = âˆ‚u/âˆ‚t + uÂ·âˆ‚u/âˆ‚x + vÂ·âˆ‚u/âˆ‚y + gÂ·(âˆ‚h/âˆ‚x + âˆ‚z/âˆ‚x) + fÂ·u
```

**Y-momentum residual (râ‚ƒ)**:
```
râ‚ƒ = âˆ‚v/âˆ‚t + uÂ·âˆ‚v/âˆ‚x + vÂ·âˆ‚v/âˆ‚y + gÂ·(âˆ‚h/âˆ‚y + âˆ‚z/âˆ‚y) + fÂ·v
```

Perfect PDE satisfaction â†’ All residuals = 0

#### 3.2.3 Initial Condition Loss (L_ic)

Enforces correct initial state:

```
L_ic = MSE(Î¶_pred(t=0) - Î¶â‚€) + MSE(u_pred(t=0) - 0) + MSE(v_pred(t=0) - 0)
```

Evaluated on a regular grid (50Ã—50 points).

#### 3.2.4 Boundary Condition Loss (L_bc)

Enforces wall boundaries:

```
L_bc = (1/4)Â·[MSE(u|_{x=0}) + MSE(u|_{x=1}) + MSE(v|_{y=0}) + MSE(v|_{y=1})]
```

Sampled at N_bc/4 = 500 random points per wall per epoch.

#### 3.2.5 Physical Constraint Loss (L_phys)

Prevents non-physical negative depth:

```
L_phys = MSE(ReLU(-h))
```

Where:
- ReLU(-h) = max(0, -h)
- Only penalizes when h < 0 (negative depth)
- Soft constraint (quadratic penalty)

### 3.3 Coordinate Normalization

#### 3.3.1 Purpose

Neural networks perform best when inputs are in similar ranges. Normalization:
- Balances gradient magnitudes across dimensions
- Prevents numerical instabilities
- Accelerates convergence
- Ensures all coordinates have equal importance

#### 3.3.2 Transformation

```
xÌ‚ = 2(x - x_min)/(x_max - x_min) - 1
Å· = 2(y - y_min)/(y_max - y_min) - 1
tÌ‚ = 2(t - t_min)/(t_max - t_min) - 1
```

Maps physical coordinates to [-1, 1]Â³.

#### 3.3.3 Scaling Factors

```python
scale_x = 2.0 / (x_max - x_min) = 2.0
scale_y = 2.0 / (y_max - y_min) = 2.0
scale_t = 2.0 / (t_max - t_min) = 0.00667
```

Used to convert derivatives back to physical coordinates via chain rule.

### 3.4 Automatic Differentiation

#### 3.4.1 PyTorch Autograd

The PINN uses PyTorch's automatic differentiation to compute all PDE derivatives:

```python
# Compute âˆ‚h/âˆ‚x
h_x_normalized = torch.autograd.grad(h, x_normalized, ...)[0]
h_x_physical = h_x_normalized * scale_x  # Chain rule
```

**Advantages**:
- Exact derivatives (no finite difference errors)
- Efficient computation (reverse-mode AD)
- Handles complex expressions automatically
- Maintains computation graph for higher-order derivatives

#### 3.4.2 Derivative Computation Steps

1. **Forward pass**: Compute NN output (Î¶, u, v)
2. **Compute h**: h = Î¶ - z(x,y)
3. **Autograd**: âˆ‚h/âˆ‚xÌ‚, âˆ‚h/âˆ‚Å·, âˆ‚h/âˆ‚tÌ‚
4. **Chain rule**: Convert to physical coordinates
5. **Residuals**: Evaluate PDE residuals
6. **Backprop**: Compute gradients of loss w.r.t. NN weights

### 3.5 Training Algorithm

#### 3.5.1 Optimizer: Adam

```python
optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)
```

**Adam features**:
- Adaptive learning rates per parameter
- Momentum for faster convergence
- Handles sparse gradients well
- Less sensitive to hyperparameters than SGD

#### 3.5.2 Learning Rate Schedule

```python
scheduler = ExponentialLR(optimizer, gamma=0.997)
```

- **Initial LR**: 5Ã—10â»â´
- **Decay**: Multiply by 0.997 each epoch
- **After 1000 epochs**: LR â‰ˆ 2.4Ã—10â»â´
- **After 10000 epochs**: LR â‰ˆ 1.0Ã—10â»â¶

Gradual decay helps fine-tune the solution in later epochs.

#### 3.5.3 Training Loop Pseudocode

```
For each epoch:
    1. Sample N_coll random collocation points in (x,y,t)
    2. Sample N_bc boundary points (N_bc/4 per wall)
    3. Forward pass: Compute NN predictions
    4. Compute terrain elevation at sampled points
    5. Calculate all PDE residuals using autograd
    6. Compute all loss components
    7. Total loss = weighted sum of components
    8. Backpropagation
    9. Optimizer step
    10. Learning rate decay step
```

#### 3.5.4 Sampling Strategy

**Collocation points** (PDE loss):
- N_coll = 10,000 random points
- Uniformly distributed in (x,y,t) domain
- New samples each epoch (stochastic training)

**Boundary points** (BC loss):
- N_bc = 2,000 total (500 per wall)
- Random spatial positions along each wall
- Random time samples

**Initial condition points** (IC loss):
- Fixed 50Ã—50 spatial grid at t=0
- 2,500 points total
- Evaluated every epoch

---

## 4. Implementation Details

### 4.1 Code Structure

```
Notebook Sections:
â”œâ”€â”€ 1. Imports and Setup
â”œâ”€â”€ 2. Domain Configuration
â”œâ”€â”€ 3. Physical Parameters
â”œâ”€â”€ 4. Terrain Definition
â”œâ”€â”€ 5. Neural Network Model
â”œâ”€â”€ 6. PDE Residual Function
â”œâ”€â”€ 7. Training Function
â”œâ”€â”€ 8. Visualization Functions
â””â”€â”€ 9. Main Execution
```

### 4.2 Key Functions

#### 4.2.1 `create_terrain_torch(X, Y)`

Creates inclined plane terrain.

**Inputs**:
- X, Y: PyTorch tensors of coordinates

**Outputs**:
- terrain: Elevation z = 0.1 - 0.05Ã—x

**Usage**:
```python
terrain = create_terrain_torch(x_collocation, y_collocation)
```

#### 4.2.2 `FloodNet` (nn.Module)

Neural network class.

**Methods**:
- `__init__()`: Initialize layers
- `init_weights()`: Xavier initialization
- `forward(x)`: Forward pass

**Usage**:
```python
model = FloodNet(in_dim=3, hid_dim=64, out_dim=3).to(device)
predictions = model(normalized_inputs)
zeta, u, v = predictions.split(1, dim=1)
```

#### 4.2.3 `shallow_water_residuals(...)`

Computes PDE residuals using automatic differentiation.

**Inputs**:
- zeta, u, v: NN predictions
- terrain_c: Terrain at collocation points
- R_source: Rainfall tensor
- Xc, Yc, Tc: Physical coordinates (with gradients)
- Xn, Yn, Tn: Normalized coordinates (with gradients)
- g, friction_factor: Physical parameters

**Outputs**:
- r1, r2, r3: Continuity and momentum residuals

**Key operations**:
1. Compute h = zeta - terrain
2. Use autograd for all derivatives
3. Convert from normalized to physical coords
4. Evaluate PDE equations

#### 4.2.4 `train_pinn(...)`

Main training loop.

**Inputs**:
- model, opt, scheduler: NN and training objects
- x_grid, y_grid: Spatial grids
- n_epochs: Number of iterations
- Loss weights, physics parameters

**Outputs**:
- loss_hist: List of loss values (sampled every 500 epochs)

**Training steps**:
- Setup initial conditions
- Loop over epochs
- Sample points
- Compute losses
- Backpropagation
- Learning rate update

#### 4.2.5 `visualize_results(...)` and `visualize_velocity_2d(...)`

Create animations.

**3D Animation**:
- Terrain surface (gray)
- Water surface (blue)
- Rotating 3D view

**2D Animation**:
- Water depth contours (blue)
- Velocity vectors (red arrows)
- Terrain contours (black lines)

### 4.3 Computational Requirements

#### 4.3.1 Hardware

**Recommended**:
- GPU: NVIDIA with 4+ GB VRAM
- CPU: 8+ cores (if no GPU)
- RAM: 8+ GB
- Storage: 500 MB for animations

**Tested on**:
- Google Colab (free tier)
- NVIDIA T4 GPU
- Training time: ~15-20 minutes

#### 4.3.2 Software Dependencies

```
Python 3.8+
torch >= 1.10
numpy >= 1.20
matplotlib >= 3.4
tqdm
jupyter / ipython
```

### 4.4 Performance Considerations

#### 4.4.1 Training Speed

Factors affecting speed:
- **N_collocation**: Linear scaling (10k points â†’ baseline)
- **Network size**: Quadratic scaling in hidden_dim
- **n_epochs**: Linear scaling
- **Device**: GPU ~10-50Ã— faster than CPU

**Typical times** (10,000 epochs, GPU):
- Training: 15 minutes
- 3D viz: 2 minutes
- 2D viz: 2 minutes
- **Total**: ~20 minutes

#### 4.4.2 Memory Usage

- **Model**: ~0.1 MB (17k parameters Ã— 4 bytes)
- **Gradients**: ~0.3 MB during backprop
- **Collocation points**: ~0.5 MB (10k points Ã— 3 coords Ã— 4 bytes)
- **Peak GPU usage**: ~2 GB

#### 4.4.3 Optimization Tips

For faster training:
```python
N_collocation = 5000  # Halve collocation points
hid_dim = 32          # Smaller network
n_epochs = 5000       # Fewer epochs
```

For better accuracy:
```python
N_collocation = 20000  # More collocation points
hid_dim = 128          # Larger network
n_epochs = 20000       # More epochs
```

---

## 5. Usage Guide

### 5.1 Quick Start

#### 5.1.1 Basic Workflow

1. **Open notebook** in Jupyter or Google Colab
2. **Run all cells** in order (Runtime â†’ Run all)
3. **Wait for training** (~15-20 minutes)
4. **View animations** at the end

#### 5.1.2 Expected Output

**During training**:
```
Epoch    0/10000 | Loss: 2.5e+02 | PDE: 1.2e+00 | IC: 8.4e+01 | ...
Epoch  500/10000 | Loss: 5.3e+01 | PDE: 2.1e-01 | IC: 1.7e+01 | ...
Epoch 1000/10000 | Loss: 1.2e+01 | PDE: 4.3e-02 | IC: 3.9e+00 | ...
...
Epoch 10000/10000 | Loss: 8.7e-01 | PDE: 1.1e-03 | IC: 2.9e-02 | ...
```

**Final outputs**:
- Loss history plot
- 3D water surface animation
- 2D velocity field animation
- Two MP4 video files

### 5.2 Modifying Parameters

#### 5.2.1 Rainfall Intensity

To change rainfall:
```python
# In "Main Execution" section
rain_mm_hr = 100.0  # Double intensity (100 mm/hr)
```

Effects:
- Higher rainfall â†’ More runoff
- Deeper water depths
- Faster velocities

#### 5.2.2 Rainfall Duration

```python
t_rain_end = 300.0  # Rain for full 5 minutes instead of 3
```

Effects:
- Longer rain â†’ More total water
- Steady-state may be reached
- Different drainage patterns

#### 5.2.3 Friction

```python
friction_factor = 0.05  # Increase friction (was 0.01)
```

Effects:
- Higher friction â†’ Slower flow
- Shallower depths (water ponds more)
- Longer time to drain

#### 5.2.4 Domain Size

```python
domain = {
    'x_max': 2.0,  # Double length (was 1.0)
    't_max': 600.0  # Double time (was 300.0)
}
```

Remember to adjust:
- Animation frame count
- Training epochs (may need more)

#### 5.2.5 Terrain Slope

```python
# In create_terrain_torch() function
slope = 0.10  # Steeper (was 0.05)
```

Effects:
- Steeper slope â†’ Faster flow
- More channelized flow
- Less ponding

### 5.3 Advanced Modifications

#### 5.3.1 Different Terrain

Replace the terrain function with custom topography:

```python
def create_terrain_torch(X, Y):
    # Example: Valley terrain
    slope_x = 0.05
    curvature_y = 0.1
    z = 0.1 - slope_x * X - curvature_y * (Y - 0.5)**2
    return z
```

#### 5.3.2 Spatially-Varying Rainfall

```python
# In train_pinn(), replace rainfall definition:
R_source_tensor = torch.where(
    ((Tc >= t_rain_start) & (Tc <= t_rain_end)) &
    (Xc > 0.25) & (Xc < 0.75),  # Only rain in center
    torch.full_like(Tc, R_const),
    torch.zeros_like(Tc)
)
```

#### 5.3.3 Network Architecture

Deeper network for complex scenarios:

```python
class FloodNet(nn.Module):
    def __init__(self, in_dim=3, hid_dim=64, out_dim=3):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_dim, hid_dim), nn.Tanh(),
            nn.Linear(hid_dim, hid_dim), nn.Tanh(),
            nn.Linear(hid_dim, hid_dim), nn.Tanh(),
            nn.Linear(hid_dim, hid_dim), nn.Tanh(),
            nn.Linear(hid_dim, hid_dim), nn.Tanh(),  # Extra layer
            nn.Linear(hid_dim, hid_dim), nn.Tanh(),  # Extra layer
            nn.Linear(hid_dim, out_dim)
        )
```

---

## 6. Parameter Tuning

### 6.1 Loss Weights

#### 6.1.1 Guidelines

**If IC is not satisfied**:
```python
w_ic = 300.0  # Increase from 150.0
```

**If BC is not satisfied** (water leaking through walls):
```python
w_bc = 300.0  # Increase from 150.0
```

**If negative depths occur**:
```python
w_phys = 50.0  # Increase from 20.0
```

**If PDE residuals are large**:
```python
w_pde = 2.0  # Increase from 1.0
```

#### 6.1.2 Balance

The weights should be balanced so all loss components are similar magnitude:

```
Ideal: PDE â‰ˆ IC â‰ˆ BC â‰ˆ Phys (after weighting)
```

Monitor during training and adjust if one dominates.

### 6.2 Learning Rate

#### 6.2.1 Too High

Symptoms:
- Loss explodes or NaN
- Erratic oscillations
- No convergence

Solution:
```python
learning_rate = 1e-4  # Reduce from 5e-4
```

#### 6.2.2 Too Low

Symptoms:
- Very slow convergence
- Loss decreases minimally
- Plateaus early

Solution:
```python
learning_rate = 1e-3  # Increase from 5e-4
n_epochs = 5000  # Can train for fewer epochs
```

### 6.3 Network Size

#### 6.3.1 Underfitting

Symptoms:
- High final loss
- Smooth but inaccurate solution
- Missing fine details

Solution:
```python
hid_dim = 128  # Increase from 64
# Or add more layers
```

#### 6.3.2 Overfitting

Symptoms:
- Very low training loss
- Unphysical oscillations
- Checkerboard patterns

Solution:
```python
hid_dim = 32  # Reduce from 64
# Or increase N_collocation
N_collocation = 20000  # More sampling points
```

### 6.4 Collocation Points

#### 6.4.1 Too Few

Symptoms:
- Large PDE residuals
- Solution doesn't satisfy physics
- Sparse coverage

Solution:
```python
N_collocation = 20000  # Increase from 10000
```

#### 6.4.2 Too Many

Symptoms:
- Very slow training
- Diminishing returns
- Memory issues

Solution:
```python
N_collocation = 5000  # Reduce from 10000
# Still maintain good accuracy
```

---

## 7. Troubleshooting

### 7.1 Common Issues

#### 7.1.1 NaN Loss

**Causes**:
- Learning rate too high
- Numerical instability in derivatives
- Division by zero in friction terms

**Solutions**:
```python
# Reduce learning rate
learning_rate = 1e-4

# Add safety epsilon
h_safe = h + 1e-6

# Clip gradients
torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
```

#### 7.1.2 Negative Depths

**Causes**:
- Insufficient physical constraint weight
- Network predicts unphysical values

**Solutions**:
```python
# Increase physical constraint weight
w_phys = 50.0  # or higher

# Add depth clamping in visualization
h_plot = np.maximum(h_np, 0)
```

#### 7.1.3 Water Leaks Through Boundaries

**Causes**:
- BC weight too low
- Insufficient BC sampling

**Solutions**:
```python
# Increase BC weight
w_bc = 300.0

# More boundary points
N_bc = 4000

# Check BC loss during training
# Should decrease to < 1e-3
```

#### 7.1.4 Slow Convergence

**Causes**:
- Learning rate too low
- Network too small
- Insufficient epochs

**Solutions**:
```python
# Increase learning rate
learning_rate = 1e-3

# Larger network
hid_dim = 128

# More epochs
n_epochs = 20000

# Use learning rate warmup
```

#### 7.1.5 Memory Errors

**Causes**:
- Too many collocation points
- Network too large
- Batch accumulation

**Solutions**:
```python
# Reduce collocation points
N_collocation = 5000

# Smaller network
hid_dim = 32

# Ensure proper cleanup
torch.cuda.empty_cache()
```

### 7.2 Validation Checks

#### 7.2.1 Mass Conservation

Check if total water volume is conserved (rainfall input = runoff + storage):

```python
# After training
with torch.no_grad():
    # Compute total water volume at final time
    T_final = torch.full_like(Xp_t, domain['t_max'])
    # ... predict and integrate h over domain
    
# Compare with expected from rainfall
expected_volume = R_const * (t_rain_end - t_rain_start) * 1.0 * 1.0
```

#### 7.2.2 Velocity Bounds

Check if velocities are physical:

```python
max_u = np.max(np.abs(u_np))
max_v = np.max(np.abs(v_np))
print(f"Max velocities: u={max_u:.3f}, v={max_v:.3f} m/s")

# Should be < 5 m/s for shallow flows
```

#### 7.2.3 Depth Bounds

```python
print(f"Min depth: {np.min(h_np):.6f} m")  # Should be â‰¥ 0
print(f"Max depth: {np.max(h_np):.6f} m")  # Should be reasonable
```

---

## 8. Extensions and Modifications

### 8.1 Physics Extensions

#### 8.1.1 Full Manning Friction

Replace linear friction with Manning's equation:

```python
def shallow_water_residuals(...):
    # ... existing code ...
    
    # Replace friction terms with Manning friction
    velocity_magnitude = torch.sqrt(u**2 + v**2 + 1e-12)
    manning_friction_x = -g * n_manning**2 * u * velocity_magnitude / (h_safe**(4/3))
    manning_friction_y = -g * n_manning**2 * v * velocity_magnitude / (h_safe**(4/3))
    
    # Update momentum residuals
    r2 = u_t + u * u_x + v * u_y + g * (h_x + z_x) + manning_friction_x
    r3 = v_t + u * v_x + v * v_y + g * (h_y + z_y) + manning_friction_y
```

#### 8.1.2 Infiltration

Add infiltration loss to continuity equation:

```python
# Define infiltration rate
K_infilt = 1e-6  # m/s (infiltration capacity)

# In PDE residuals
R_net = R_source - K_infilt  # Net source term
r1 = h_t + u * h_x + h * u_x + v * h_y + h * v_y - R_net
```

#### 8.1.3 Sediment Transport

Add sediment concentration as 4th output:

```python
class FloodNet(nn.Module):
    def __init__(self, in_dim=3, hid_dim=64, out_dim=4):  # 4 outputs
        # ... (Î¶, u, v, c) where c is sediment concentration

# Add sediment transport equation to residuals
# âˆ‚c/âˆ‚t + uÂ·âˆ‚c/âˆ‚x + vÂ·âˆ‚c/âˆ‚y = erosion - deposition
```

### 8.2 Domain Extensions

#### 8.2.1 Larger Domain

```python
domain = {
    'x_max': 10.0,  # 10m slope
    'y_max': 5.0,   # 5m width
    't_max': 600.0  # 10 minutes
}

# May need more collocation points
N_collocation = 20000
```

#### 8.2.2 3D Domain (Full Navier-Stokes)

Extend to full 3D shallow water or even Navier-Stokes:
- Add z-coordinate
- Add w-velocity
- Include vertical structure

#### 8.2.3 Multiple Slopes

```python
def create_terrain_torch(X, Y):
    # Piecewise terrain
    z1 = 0.1 - 0.05 * X  # First slope
    z2 = 0.05 - 0.02 * X  # Second slope
    z = torch.where(X < 0.5, z1, z2)
    return z
```

### 8.3 Computational Extensions

#### 8.3.1 Transfer Learning

Train on simple case, fine-tune for complex:

```python
# Train on inclined plane
model1 = FloodNet().to(device)
train_pinn(model1, ...)

# Save model
torch.save(model1.state_dict(), 'base_model.pth')

# Load for new scenario
model2 = FloodNet().to(device)
model2.load_state_dict(torch.load('base_model.pth'))

# Fine-tune with new terrain/rainfall
train_pinn(model2, n_epochs=2000, ...)  # Fewer epochs needed
```

#### 8.3.2 Multi-Fidelity Learning

Combine PINN with low-fidelity data:

```python
# Add data loss term
L_data = MSE(h_pred(x_data, t_data) - h_measured)

# Total loss
L_total = w_pde * L_pde + w_data * L_data + ...
```

#### 8.3.3 Adaptive Sampling

Sample more points where residuals are high:

```python
# During training
with torch.no_grad():
    residuals = compute_residuals(...)
    high_error_mask = residuals > threshold

# Next epoch: sample more points in high-error regions
```

### 8.4 Visualization Extensions

#### 8.4.1 Real-Time Monitoring

```python
# During training, periodically visualize
if epoch % 1000 == 0:
    plot_current_solution(model, epoch)
```

#### 8.4.2 Interactive 3D

```python
# Use plotly instead of matplotlib
import plotly.graph_objects as go

fig = go.Figure(data=[
    go.Surface(x=X, y=Y, z=terrain),
    go.Surface(x=X, y=Y, z=zeta, opacity=0.7)
])
fig.show()
```

#### 8.4.3 Streamlines

```python
# Add streamline visualization
from matplotlib import streamplot

fig, ax = plt.subplots()
ax.streamplot(X, Y, u_np, v_np, color=h_np, cmap='Blues')
```

---

## 9. References

### 9.1 Theory

#### 9.1.1 Shallow Water Equations

1. Toro, E. F. (2001). *Shock-Capturing Methods for Free-Surface Shallow Flows*. Wiley.
2. LeVeque, R. J. (2002). *Finite Volume Methods for Hyperbolic Problems*. Cambridge University Press.

#### 9.1.2 Physics-Informed Neural Networks

1. Raissi, M., Perdikaris, P., & Karniadakis, G. E. (2019). *Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations*. Journal of Computational Physics, 378, 686-707.

2. Karniadakis, G. E., et al. (2021). *Physics-informed machine learning*. Nature Reviews Physics, 3(6), 422-440.

### 9.2 Implementation

#### 9.2.1 PyTorch

- Official Documentation: https://pytorch.org/docs/
- Autograd Tutorial: https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html

#### 9.2.2 PINN Examples

- DeepXDE: https://github.com/lululxvi/deepxde
- NeuralPDE.jl: https://github.com/SciML/NeuralPDE.jl

### 9.3 Applications

#### 9.3.1 Hydrology

1. Chen, Y., et al. (2020). *Physics-informed neural networks for shallow water equations*.
2. Singh, V. P. (1996). *Kinematic Wave Modeling in Water Resources: Surface-Water Hydrology*. Wiley.

#### 9.3.2 Flood Modeling

1. Bates, P. D., & De Roo, A. P. J. (2000). *A simple raster-based model for flood inundation simulation*. Journal of Hydrology, 236(1-2), 54-77.

---

## Appendix A: Notation Summary

| Symbol | Description | Units |
|--------|-------------|-------|
| x, y | Spatial coordinates | m |
| t | Time | s |
| h | Water depth | m |
| u, v | Velocity components | m/s |
| z | Terrain elevation | m |
| Î¶ | Water surface elevation | m |
| R | Rainfall intensity | m/s |
| g | Gravitational acceleration | m/sÂ² |
| f | Friction coefficient | 1/s |
| n | Manning's roughness | s/m^(1/3) |
| L | Loss function | - |
| w | Loss weight | - |
| r | PDE residual | [varies] |
| Î¸ | Neural network parameters | - |
| N | Number of sample points | - |

---

## Appendix B: Default Parameters

```python
# Domain
domain = {'x_min': 0.0, 'x_max': 1.0, 'y_min': 0.0, 'y_max': 1.0, 
          't_min': 0.0, 't_max': 300.0}

# Sampling
N_collocation = 10000
N_bc = 2000
N_ic = 2500

# Network
in_dim = 3
hid_dim = 64
out_dim = 3
activation = 'Tanh'

# Training
n_epochs = 10000
learning_rate = 5e-4
scheduler_gamma = 0.997

# Loss weights
w_pde = 1.0
w_ic = 150.0
w_bc = 150.0
w_phys = 20.0

# Physics
g = 9.81  # m/sÂ²
friction_factor = 0.01  # 1/s
rain_mm_hr = 50.0  # mm/hr
t_rain_start = 0.0  # s
t_rain_end = 180.0  # s

# Terrain
slope = 0.05  # 5%
z_max = 0.1  # m
```

---

## Appendix C: Computational Cost Analysis

### Memory Complexity

- **Model**: O(L Ã— HÂ²) where L = layers, H = hidden_dim
- **Forward pass**: O(N Ã— H) where N = batch_size
- **Backward pass**: O(N Ã— H Ã— L)
- **Total GPU**: ~2 GB for default params

### Time Complexity

- **Forward pass**: O(N Ã— HÂ² Ã— L)
- **Autograd**: O(N Ã— H Ã— L) per derivative
- **Total PDE residuals**: O(N Ã— H Ã— L Ã— D) where D = num_derivatives
- **One epoch**: O(N_coll Ã— HÂ² Ã— L)
- **Full training**: O(n_epochs Ã— N_coll Ã— HÂ² Ã— L)

### Scaling Laws

Training time scales as:
- Linear in n_epochs
- Linear in N_collocation
- Quadratic in hid_dim
- Linear in num_layers

---

## Document Information

**Version**: 1.0  
**Date**: February 2026  
**Author**: Physics-Informed ML Documentation  
**Purpose**: Complete reference for PINN rainfall-runoff model

**Document Status**: Complete  
**Review Status**: Reviewed  
**Distribution**: Public

---

*End of Documentation*
